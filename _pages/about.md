---
permalink: /
title: ""
excerpt: ""
author_profile: true
redirect_from: 
  - /about/
  - /about.html
---

{% if site.google_scholar_stats_use_cdn %}
{% assign gsDataBaseUrl = "https://cdn.jsdelivr.net/gh/" | append: site.repository | append: "@" %}
{% else %}
{% assign gsDataBaseUrl = "https://raw.githubusercontent.com/" | append: site.repository | append: "/" %}
{% endif %}
{% assign url = gsDataBaseUrl | append: "google-scholar-stats/gs_data_shieldsio.json" %}

<!-- <span class='anchor' id='about-me'></span> -->

# ü§µ Introduction
The Intelligent Sensing and Computing Laboratory is dedicated to advancing the field of intelligent detection and information processing through innovative research and cutting-edge technology. Rooted in the robust theoretical foundations of deep learning and multimodal large models, our laboratory spearheads efforts in developing state-of-the-art methodologies and applications.
Our research portfolio spans a diverse range of areas including target detection, pedestrian re-identification, behavior analysis, and multimodal intelligent human-machine interaction. In addition, we explore advanced techniques in infrared image processing, optical fiber signal intelligent detection, and biomedical signal analysis. By integrating these disciplines, we aim to create intelligent systems that can efficiently and accurately interpret complex data from various sources.
Committed to pushing the boundaries of artificial intelligence, our laboratory focuses on both theoretical research and practical implementations. We strive to address real-world challenges by developing novel algorithms and systems, fostering an environment of interdisciplinary collaboration, and contributing to the evolution of intelligent sensing and computing technologies.

# üíª Dataset 
<div class='paper-box'><div class='paper-box-image'><div><div class="badge"></div><img src='images/fig3.png' alt="sym" width="100%"></div></div>
<div class='paper-box-text' markdown="1">

**Mouse pose dataset from open-field test (MPD-OFT)** \\
The MPD-OFT dataset employs a top‚Äìdown perspective. The closed-circuit television (CCTV) cameras are set
 at different heights to accommodate different sizes and shapes
 of open fields, such as small rectangular open fields, spacious
 circular water mazes, or Y-shaped and cross mazes, ensuring
 full coverage of the experimental areas. As shown in the figure,
(a) Top-view open-field conditions aimed to record the natural behavior of the mouse in system setup diagram. (b) and
 (c) Rectangular open-field images. (d)‚Äì(f) Cross-maze open-field images.
 (g) Morris circle water maze image. (h) Y-maze image.
**Features**
- Diversity of Open Field
- Multiheight and Multiresolution Camera Settings
- Open Scene With Background
</div>
</div>

# üìù Publication 

<div class='paper-box'><div class='paper-box-image'><div><div class="badge">TIM 2025</div><img src='images/fig7.png' alt="sym" width="100%"></div></div>
<div class='paper-box-text' markdown="1">

[YOLO-MousePose: A Novel Framework and Dataset for Mouse Pose Estimation From a Top‚ÄìDown View](https://ieeexplore.ieee.org/document/10929680)\\
Mingxin Yu, **Hao Dong**, Rui You, Shengjun Liang, Qihao Zhang, Yiyuan Ge, Mingwei LinÔºåZeshui Xu\\
**Keywords**
- Pose estimation
- Mice
- Feature extraction
- Deep learning
</div>
</div>







# üìñ Dataset Usage Guidelines
This dataset is released solely for research and educational purposes. Commercial use in any form is strictly prohibited. Users must comply with all applicable laws and regulations when accessing or using this dataset. Any use of the dataset, in whole or in part, for commercial purposes‚Äîincluding but not limited to product development, commercial services, demonstrations, or redistribution‚Äîis not permitted. Publications or reports that utilize this dataset must acknowledge its source.
We kindly ask users to cite the following paper when using this dataset:
Mingxin Yu, Hao Dong, Rui You, Shengjun Liang, Qihao Zhang, Yiyuan Ge, Mingwei Lin, and Zeshui Xu,
"YOLO-MousePose: A Novel Framework and Dataset for Mouse Pose Estimation From a Top‚ÄìDown View,"
IEEE Transactions on Instrumentation and Measurement, vol. 74, pp. 1‚Äì19, 2025, Art no. 5019319,
doi: 10.1109/TIM.2025.3551854.
We also gratefully acknowledge the support of the Intelligent Sensing and Computing Laboratory, Beijing Information Science and Technology University, for the development and release of this dataset.



# üìñ Acknowledgements
We would like to express our sincere gratitude to Mr. Qihao Zhang from Beijing Qiaqia Cloud Technology Co., Ltd. for providing the original dataset. We thank Hao Dong for his significant contributions to data organization, annotation, model construction, training, testing, and manuscript writing. We are also grateful to Shengjun Liang and Yiyuan Ge for their valuable guidance on data analysis and model development. Special thanks go to Xufan Miao and Chengda Yao from our laboratory for their dedicated efforts in data annotation.

# üìñ How to get the dataset
**If you need to obtain the dataset, please contact [yumingxin@bistu.edu.cn](yumingxin@bistu.edu.cn) or [540083559@qq.com](540083559@qq.com)**

<script type="text/javascript" src="//rf.revolvermaps.com/0/0/6.js?i=54e0ojatafc&amp;m=7&amp;c=e63100&amp;cr1=ffffff&amp;f=arial&amp;l=0&amp;bv=90&amp;lx=-420&amp;ly=420&amp;hi=20&amp;he=7&amp;hc=a8ddff&amp;rs=80" async="async"></script>
